{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from matplotlib.image import imread\n",
    "\n",
    "\n",
    "\n",
    "train_path =\"panneaux\\Dataset\\Train\"\n",
    "test_path = \"panneaux\\Dataset\\Test\"\n",
    "\n",
    "\n",
    "IMG_SIZE = (32, 32)\n",
    "\n",
    "\n",
    "classes_number = len(os.listdir(train_path))\n",
    "print(f\"Nombre de classes: {classes_number}\")\n",
    "\n",
    "\n",
    "classes = { \n",
    "    0:'Speed limit (20km/h)',\n",
    "    1:'Speed limit (30km/h)',\n",
    "    2:'Speed limit (50km/h)',\n",
    "    3:'Speed limit (60km/h)',\n",
    "    4:'Speed limit (70km/h)',\n",
    "    5:'Speed limit (80km/h)',\n",
    "    6:'End of speed limit (80km/h)',\n",
    "    7:'Speed limit (100km/h)',\n",
    "    8:'Speed limit (120km/h)',\n",
    "    9:'No passing',\n",
    "    10:'No passing veh over 3.5 tons',\n",
    "    11:'Right-of-way at intersection',\n",
    "    12:'Priority road',\n",
    "    13:'Yield',\n",
    "    14:'Stop',\n",
    "    15:'No vehicles',\n",
    "    16:'Veh > 3.5 tons prohibited',\n",
    "    17:'No entry',\n",
    "    18:'General caution',\n",
    "    19:'Dangerous curve left',\n",
    "    20:'Dangerous curve right',\n",
    "    21:'Double curve',\n",
    "    22:'Bumpy road',\n",
    "    23:'Slippery road',\n",
    "    24:'Road narrows on the right',\n",
    "    25:'Road work',\n",
    "    26:'Traffic signals',\n",
    "    27:'Pedestrians',\n",
    "    28:'Children crossing',\n",
    "    29:'Bicycles crossing',\n",
    "    30:'Beware of ice/snow',\n",
    "    31:'Wild animals crossing',\n",
    "    32:'End speed + passing limits',\n",
    "    33:'Turn right ahead',\n",
    "    34:'Turn left ahead',\n",
    "    35:'Ahead only',\n",
    "    36:'Go straight or right',\n",
    "    37:'Go straight or left',\n",
    "    38:'Keep right',\n",
    "    39:'Keep left',\n",
    "    40:'Roundabout mandatory',\n",
    "    41:'End of no passing',\n",
    "    42:'End no passing veh > 3.5 tons' \n",
    "}\n",
    "\n",
    "\n",
    "folders = os.listdir(train_path)\n",
    "\n",
    "train_number = []\n",
    "class_num = []\n",
    "\n",
    "for folder in folders:\n",
    "    train_files = os.listdir(train_path + '/' + folder)\n",
    "    train_number.append(len(train_files))\n",
    "    class_num.append(classes[int(folder)])\n",
    "\n",
    "zipped_lists = zip(train_number, class_num)\n",
    "sorted_pairs = sorted(zipped_lists)\n",
    "tuples = zip(*sorted_pairs)\n",
    "train_number, class_num = [list(tuple) for tuple in tuples]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(class_num, train_number)\n",
    "plt.title(\"Distribution des classes dans le jeu d'entrainement\")\n",
    "plt.xlabel(\"Nombre d'images\")\n",
    "plt.ylabel(\"Classes\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    folders = sorted(os.listdir(data_dir))  \n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        for image_file in os.listdir(folder_path):\n",
    "            if image_file.lower().endswith(('.png', '.jpg', '.jpeg')): \n",
    "                image_path = os.path.join(folder_path, image_file)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    print(\"Impossible de lire:\", image_path)\n",
    "                    continue\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMG_SIZE)\n",
    "                images.append(image)\n",
    "                labels.append(int(folder))  \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def load_test_data(test_dir, csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        image_path = os.path.join(test_dir, os.path.basename(row['Path']))\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(\"Fichier non trouvé :\", image_path)\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, IMG_SIZE)\n",
    "        images.append(image)\n",
    "        labels.append(row['ClassId'])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Chargement des donnees d'entraenement...\")\n",
    "X_train, y_train = load_data(train_path)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train \n",
    ")\n",
    "print(\"Chargement des donnees de test...\")\n",
    "test_csv = r\"D:\\sara_projects\\projets\\panneaux\\Dataset\\Test.csv\"\n",
    "X_test, y_test = load_test_data(test_path, test_csv)\n",
    "\n",
    "# Normalisation + categoriel conversion \n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Conversion des labels en one-hot\n",
    "y_train_categorical = to_categorical(y_train, classes_number)\n",
    "y_val_categorical = to_categorical(y_val, classes_number)\n",
    "y_test_categorical = to_categorical(y_test, classes_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=False, \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "print(\"Data Augmentation configurée!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN  model\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        # first \n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(2, 2),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # 2 couche convolutive\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(2, 2),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # 3eme couche convolutive\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(2, 2),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # fully connected\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(classes_number, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_cnn_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# model trainning\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.0001\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train_categorical, batch_size=32),\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val_categorical),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train_categorical, batch_size=32),\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val_categorical),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69622947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#evaluation\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy du modèle')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss du modèle')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n",
    "print(f\"Accuracy sur le jeu de test: {test_accuracy:.4f}\")\n",
    "print(f\"Loss sur le jeu de test: {test_loss:.4f}\")\n",
    "\n",
    "# Matrice de confusion et rapport \n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=list(classes.values())[:10],  # Afficher seulement les 10 premières classes pour la lisibilité\n",
    "            yticklabels=list(classes.values())[:10])\n",
    "plt.title('Matrice de Confusion (10 premières classes)')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies étiquettes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Rapport de classification:\")\n",
    "print(classification_report(y_test, y_pred_classes, \n",
    "                          target_names=list(classes.values())))\n",
    "\n",
    "def visualize_predictions(images, true_labels, pred_labels, classes_dict, num_samples=10):\n",
    "    \"\"\"\n",
    "    Visualise quelques prédictions du modèle\n",
    "    \"\"\"\n",
    "    indices = random.sample(range(len(images)), num_samples)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(images[idx])\n",
    "        \n",
    "        true_label = classes_dict[true_labels[idx]]\n",
    "        pred_label = classes_dict[pred_labels[idx]]\n",
    "        \n",
    "        color = 'green' if true_labels[idx] == pred_labels[idx] else 'red'\n",
    "        plt.title(f'Vrai: {true_label}\\nPrédit: {pred_label}', color=color, fontsize=8)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(X_test, y_test, y_pred_classes, classes)\n",
    "\n",
    "model.save('traffic_sign_classifier.h5')\n",
    "\n",
    "\n",
    "def predict_traffic_sign(image_path, model, classes_dict):\n",
    "    \n",
    "  \n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, IMG_SIZE)\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    \n",
    "    prediction = model.predict(image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = np.max(prediction)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Prédiction: {classes_dict[predicted_class]}\\nConfiance: {confidence:.2f}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return classes_dict[predicted_class], confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
